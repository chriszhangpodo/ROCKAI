{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a002502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd8f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b90999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514bcf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-4.3.1.tar.gz (13 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from gdown) (4.9.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from gdown) (4.62.3)\n",
      "Requirement already satisfied: requests[socks] in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from gdown) (2.26.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from beautifulsoup4->gdown) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests[socks]->gdown) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests[socks]->gdown) (2.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests[socks]->gdown) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests[socks]->gdown) (3.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.3.1-py3-none-any.whl size=14493 sha256=b8a25c1c9532e4025e031474096520f429c68f6edda728e187d94172b28becc4\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/d1/1b/3e/f03df6be3040b0f9a1a29db63caba2d18ae5aa869217dc4199\n",
      "Successfully built gdown\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-4.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e11a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://drive.google.com/file/d/1mPBHTBWnoAKOf21niapRghwI1dhsnim9/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88dd6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1mPBHTBWnoAKOf21niapRghwI1dhsnim9\n",
      "To: /home/ec2-user/SageMaker/Explore/Chris/rockAI/rockai_images.tgz\n",
      "100%|██████████| 1.76G/1.76G [00:44<00:00, 39.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rockai_images.tgz'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=1mPBHTBWnoAKOf21niapRghwI1dhsnim9'\n",
    "output = 'rockai_images.h5'\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d95fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    import h5py\n",
    "    import numpy as np\n",
    "    h5f = h5py.File(filepath, 'r')\n",
    "    X = h5f['X'][:]\n",
    "    classnames = [s.decode('utf-8') for s in h5f['classname'][:]]\n",
    "    filenames = [s.decode('utf-8') for s in h5f['filename'][:]]\n",
    "    h5f.close()\n",
    "    return X, np.array(classnames), np.array(filenames)\n",
    "\n",
    "def create_train_test_idx(classnames):\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(data=enumerate(classnames), columns=['index', 'classname'])\n",
    "    test_df = None\n",
    "    train_df = None\n",
    "    for classname in df['classname'].unique():\n",
    "        test_tmp_df = df[df['classname']==classname].sample(50, replace=False, random_state=1234)\n",
    "        train_tmp_df = df[(df['classname']==classname) & ~(df['index'].isin(test_tmp_df['index']))]\n",
    "        test_df = test_tmp_df if test_df is None else pd.concat([test_df, test_tmp_df])\n",
    "        train_df = train_tmp_df if train_df is None else pd.concat([train_df, train_tmp_df])    \n",
    "    return train_df['index'].values, test_df['index'].values\n",
    "    \n",
    "X, classnames, filenames = load_data('rockai_images.h5')\n",
    "train_idx, test_idx = create_train_test_idx(classnames)\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train = [classnames[i] for i in train_idx]\n",
    "y_test = [classnames[i] for i in test_idx]\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "#Pre-process the data\n",
    "X_train = preprocess_input(X_train)\n",
    "X_test = preprocess_input(X_test)\n",
    "y_train = [0 if x=='No_RA' else 1 for x in y_train]\n",
    "y_test = [0 if x=='No_RA' else 1 for x in y_test]\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581b380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da04c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in resnet_model.layers:\n",
    "    \n",
    "    if isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(resnet_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5f551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_random():\n",
    "    X, classnames, filenames = load_data('rockai_images.h5')\n",
    "    train_idx, test_idx = create_train_test_idx(classnames)\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train = [classnames[i] for i in train_idx]\n",
    "    y_test = [classnames[i] for i in test_idx]\n",
    "\n",
    "    #Pre-process the data\n",
    "    X_train = preprocess_input(X_train)\n",
    "    X_test = preprocess_input(X_test)\n",
    "    y_train = [0 if x=='No_RA' else 1 for x in y_train]\n",
    "    y_test = [0 if x=='No_RA' else 1 for x in y_test]\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19f0fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix,accuracy_score\n",
    "def run_model(X_train, y_train, X_test, y_test):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True))\n",
    "    # datagen = ImageDataGenerator()\n",
    "    datagen.fit(X_train)\n",
    "    batch_size = 32\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    historytemp = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                        epochs=30)\n",
    "    # evaluate the model\n",
    "    y_pred1 = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred1, axis=1)\n",
    "    #y_test_bool = np.argmax(y_test, axis=1)\n",
    "    #f = f1_score(y_test_bool, y_pred , average=\"macro\")\n",
    "    #a = accuracy_score(y_test_bool, y_pred)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f786fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, X_test, y_test = run_data_random()\n",
    "trx = []\n",
    "tex = []\n",
    "trY = []\n",
    "teY = []\n",
    "for i in range(3):\n",
    "    X_train, y_train, X_test, y_test = run_data_random()\n",
    "    trx.append(X_train)\n",
    "    tex.append(X_test)\n",
    "    trY.append(y_train)\n",
    "    teY.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f34f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 43 steps\n",
      "Epoch 1/30\n",
      "43/43 [==============================] - 40s 939ms/step - loss: 0.0761 - accuracy: 0.9831\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 31s 721ms/step - loss: 0.0297 - accuracy: 0.9912\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 31s 717ms/step - loss: 0.0167 - accuracy: 0.9963\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 0.0115 - accuracy: 0.9985\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 31s 715ms/step - loss: 0.0064 - accuracy: 0.9993\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 31s 715ms/step - loss: 0.0088 - accuracy: 0.9978\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 33s 757ms/step - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 31s 716ms/step - loss: 0.0059 - accuracy: 0.9978\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 31s 715ms/step - loss: 0.0059 - accuracy: 0.9993\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 31s 715ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 31s 716ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 33s 759ms/step - loss: 0.0099 - accuracy: 0.9956\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 31s 716ms/step - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 31s 715ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 31s 716ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 31s 716ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 31s 717ms/step - loss: 8.0097e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 33s 760ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 31s 718ms/step - loss: 0.0061 - accuracy: 0.9993\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 31s 716ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 31s 718ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 31s 719ms/step - loss: 8.1474e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 31s 717ms/step - loss: 9.7090e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 33s 762ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 31s 718ms/step - loss: 8.6495e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 31s 717ms/step - loss: 3.6189e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 31s 716ms/step - loss: 9.6749e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 31s 717ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 31s 721ms/step - loss: 0.0049 - accuracy: 0.9993\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 33s 762ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "done for one repeat\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 43 steps\n",
      "Epoch 1/30\n",
      "43/43 [==============================] - 39s 901ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 31s 719ms/step - loss: 0.0061 - accuracy: 0.9993\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 31s 716ms/step - loss: 0.0054 - accuracy: 0.9985\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 33s 757ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 0.0087 - accuracy: 0.9985\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 0.0057 - accuracy: 0.9978\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 0.0038 - accuracy: 0.9978\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 33s 757ms/step - loss: 7.2911e-04 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 7.1846e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 6.4512e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 31s 711ms/step - loss: 5.9419e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 33s 756ms/step - loss: 8.0538e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 0.0076 - accuracy: 0.9978\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 5.4363e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 5.5686e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 32s 744ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 0.0015 - accuracy: 0.9985\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 4.2081e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 31s 714ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 31s 714ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 33s 758ms/step - loss: 8.6848e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 31s 710ms/step - loss: 4.8294e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 2.0843e-04 - accuracy: 1.0000\n",
      "done for one repeat\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 43 steps\n",
      "Epoch 1/30\n",
      "43/43 [==============================] - 38s 890ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 31s 723ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 31s 717ms/step - loss: 0.0036 - accuracy: 0.9985\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 32s 755ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 2.6265e-04 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 31s 711ms/step - loss: 3.9006e-04 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 31s 710ms/step - loss: 0.0023 - accuracy: 0.9985\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 31s 711ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 31s 710ms/step - loss: 3.8528e-04 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 32s 754ms/step - loss: 5.3993e-04 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 31s 711ms/step - loss: 1.5990e-04 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 31s 711ms/step - loss: 9.7692e-05 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 31s 710ms/step - loss: 2.2066e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 31s 710ms/step - loss: 9.2398e-05 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 32s 754ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 31s 717ms/step - loss: 5.0413e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 6.0266e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 31s 710ms/step - loss: 5.3703e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 3.0761e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 32s 755ms/step - loss: 4.6412e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 1.8099e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 31s 711ms/step - loss: 8.4923e-05 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 1.9823e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 3.0637e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 31s 711ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 32s 755ms/step - loss: 1.1629e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 31s 712ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 31s 715ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 31s 714ms/step - loss: 0.0076 - accuracy: 0.9963\n",
      "done for one repeat\n"
     ]
    }
   ],
   "source": [
    "pred_all= []\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    y_pred = run_model(trx[i],trY[i],tex[i],teY[i])\n",
    "    pred_all.append(y_pred)\n",
    "    print('done for one repeat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e608f069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.84]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "070e3c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8357963875205254]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e8c38f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87 0.8849557522123894\n"
     ]
    }
   ],
   "source": [
    "y_test_bool = np.argmax(y_test, axis=1)\n",
    "a = accuracy_score(y_test_bool, pred_all[0])\n",
    "f = f1_score(y_test_bool, pred_all[0])\n",
    "print(a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40f2dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89 0.9009009009009009\n"
     ]
    }
   ],
   "source": [
    "a = accuracy_score(y_test_bool, pred_all[1])\n",
    "f = f1_score(y_test_bool, pred_all[1])\n",
    "print(a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7c18d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "a = accuracy_score(y_test_bool, pred_all[2])\n",
    "f = f1_score(y_test_bool, pred_all[2])\n",
    "print(a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33725de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8866666666666667\n",
      "0.8955666666666667\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([0.87,0.89,0.9]))\n",
    "print(np.mean([0.8849,0.90090,0.90090]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2963e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
